{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d167c6c-06a6-4dd2-9c83-85867017f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dee711b-9592-4114-9881-ec403532eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5sum(x):\n",
    "    return hashlib.md5(x.encode(\"utf-8\")).hexdigest()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4458945-1682-44b7-9205-0c2cdcff51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['carpedeam2.configSafe', 'carpedeam2.configUnsafe', 'megahit.config0', 'penguin.config0', 'spades.config0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77b6b38-60f9-4196-b0f0-ebc68f540f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"ancientCalc\", \"ancientGut\", \"ancientHorse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd2524-c120-4976-84d3-d7b0d8c4c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"gut_sum_high_c3\", \"gut_sum_high_c5\", \"gut_sum_high_c10\", \"gut_sum_mid_c3\", \"gut_sum_mid_c5\", \"gut_sum_mid_c10\", \\\n",
    " \"calc_2095_high_c3\", \"calc_2095_high_c5\", \"calc_2095_high_c10\", \"calc_2095_mid_c3\", \"calc_2095_mid_c5\", \"calc_2095_mid_c10\", \\\n",
    " \"horse_sum_high_c3\", \"horse_sum_high_c5\", \"horse_sum_high_c10\", \"horse_sum_mid_c3\", \"horse_sum_mid_c5\", \"horse_sum_mid_c10\"]\n",
    "\n",
    "labels_clean = [\n",
    "    \"Gut:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Gut:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Gut:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 3X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 5X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 10X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 3X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 5X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 10X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 3X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 5X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 10X\"\n",
    "]\n",
    "\n",
    "labels_dict = {key: get_md5sum(key) for key in labels}\n",
    "labels_dict_inv = {value: key for key, value in labels_dict.items()}\n",
    "print(labels_dict_inv)\n",
    "\n",
    "labels_dict_clean = {labels[i] : labels_clean[i] for i in range(len(labels))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_assembler(cell):\n",
    "    if \"carpedeam\" in cell:\n",
    "        return \"CarpeDeam\"\n",
    "    elif \"penguin\" in cell:\n",
    "        return \"PenguiN\"\n",
    "    elif \"megahit\" in cell:\n",
    "        return \"MEGAHIT\"\n",
    "    elif \"spades\" in cell:\n",
    "        return \"metaSPAdes\"\n",
    "    else:\n",
    "        return cell  # Return the cell as is if none of the conditions are met\n",
    "\n",
    "def adjust_assemblerconfig(row):\n",
    "    if row[\"assembler\"] == \"CarpeDeam\":\n",
    "        if \"Safe\" in row[\"file\"]:\n",
    "            return \"CarpeDeam (safe mode)\"\n",
    "        elif \"Unsafe\" in row[\"file\"]:\n",
    "            return \"CarpeDeam (unsafe mode)\"\n",
    "        else:\n",
    "            return \"CarpeDeam\\n(safe mode)\"\n",
    "    else:\n",
    "        return row[\"assembler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5da30fa-dfe3-45ce-af74-329965e2bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_report_df(file):\n",
    "    \"\"\"\n",
    "    Returns a list of dataframes. Each dataframe belongs to a file/assembler. The analyzed files are from mmseq taxonomy:\n",
    "    (1) Query\n",
    "    (2) Target\n",
    "    (3) Seq.Id.\n",
    "    (4) Alignment Length\n",
    "    (5) Number of mismatches\n",
    "    (6) number of gap openings\n",
    "    (7) Start in Query\n",
    "    (8) End in Query\n",
    "    (9) Start in Target\n",
    "    (10) End in Target\n",
    "    (11) Eval\n",
    "    (12) bit score\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the file into a pandas DataFrame\n",
    "    df_aln = pd.read_csv(file, sep='\\t', names=[\"query\", \"target\", \"seq.Id.\", \"alnLen\", \"MM\", \"gaps\", \"startQuery\", \"EndQuery\", \"startTarget\", \\\n",
    "                                                 \"EndTarget\", \"Eval\", \"bit score\", \"queryLen\", \"targetLen\", \"queryCov\", \"targetCov\"])\n",
    "\n",
    "    unique_targets = df_aln['target'].nunique()\n",
    "    \n",
    "    # Convert columns to numpy arrays for faster filtering\n",
    "    seq_id = df_aln[\"seq.Id.\"].to_numpy()\n",
    "    evals = df_aln[\"Eval\"].to_numpy()\n",
    "    aln_len = df_aln[\"alnLen\"].to_numpy()\n",
    "    target_cov = df_aln[\"targetCov\"].to_numpy()\n",
    "    \n",
    "    # Apply the filters using numpy boolean indexing\n",
    "    filter_mask = (seq_id >= 0.9) & (evals <= 1e-5) & (aln_len >= 100) & (target_cov >= 0.9)\n",
    "    df_aln_filtered = df_aln[filter_mask]\n",
    "\n",
    "    unique_hits = df_aln_filtered['target'].nunique()\n",
    "\n",
    "    if unique_targets != 0:\n",
    "        ratio = unique_hits/unique_targets\n",
    "    else:\n",
    "        ratio = 0\n",
    "    \n",
    "    return unique_targets, ratio, unique_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808b7a11-429f-4869-be27-f662f89ac076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_protein_matches(directory, configs, damage):\n",
    "    # Find all FASTA files in the specified directory\n",
    "    tsv_files = glob.glob(os.path.join(directory, \"*.tsv\"))\n",
    "    \n",
    "    # Dictionary to store the information\n",
    "    protein_info = {}\n",
    "\n",
    "    for file in tsv_files:\n",
    "\n",
    "        if not any(config in file for config in configs):\n",
    "            continue\n",
    "\n",
    "        name = os.path.basename(file)\n",
    "        assembler = re.search(r'mmseqs.([a-zA-Z0-9]+).config', name).group(1)\n",
    "        label = re.match(r'([a-z0-9]+).raw', name).group(1)\n",
    "        label_human = labels_dict_inv.get(label, \"ERROR\")  # Replace default_value with the desired default if label is not found\n",
    "        dam = label_human.split(\"_\")[2]\n",
    "        if dam != damage:\n",
    "            continue\n",
    "        \n",
    "        config = re.search(r'config(\\d+)', name).group(1)\n",
    "        \n",
    "        unique_targets, ratio, unique_hits = curate_report_df(file)\n",
    "        #unique_hits = df_file['target'].nunique()\n",
    "        \n",
    "        protein_info[name] = [assembler, label, config, unique_hits, unique_targets, ratio]\n",
    "        print(name)\n",
    "        \n",
    "\n",
    "    print(\"iteration done\")\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame.from_dict(protein_info, orient='index', columns=['Assembler', 'Label', 'Config', 'UniqueHits', 'UniqueTargets', 'Ratio Hits'])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'Filename'}, inplace=True)\n",
    "\n",
    "    # Add additional columns\n",
    "    df[\"assemblerconfig\"] = df[\"Assembler\"] + \" \" + df[\"Config\"]\n",
    "    df[\"assembler_clean\"] = df[\"Assembler\"].apply(map_assembler)\n",
    "    df[\"assembler_final\"] = df.apply(adjust_assemblerconfig, axis=1)\n",
    "    df[\"label\"] = df[\"Label\"].astype(str)\n",
    "    df[\"label_human\"] = df[\"Label\"].map(labels_dict_inv)\n",
    "    df[\"label_clean\"] = df[\"label_human\"].replace(labels_dict_clean)\n",
    "    df[\"dataset_clean\"] = df[\"label_clean\"].str.split(\":\").str[0]\n",
    "    df[\"coverage\"] = df[\"label_human\"].str.split(\"_\").str[3].str[1::]\n",
    "    df[\"damage\"] = df[\"label_human\"].str.split(\"_\").str[2]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae87ad6e-82e7-4141-be6b-9f3f4d68d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_df(datasets, configs, damage):\n",
    "\n",
    "    dfs = []\n",
    "    for data in datasets:\n",
    "        directory = f\"data/{data}/results/assembly-mmseqs/fasta_vs_prokka\"\n",
    "        df = filter_protein_matches(directory, configs, damage)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f788404e-35da-4b76-b8d0-8af09bb60736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_correct_horizontal(df_orig, damage, bar_width=1):\n",
    "    # Filter dataframe based on damage\n",
    "    df = df_orig[df_orig[\"damage\"] == damage]\n",
    "    \n",
    "    # Define a custom palette for consistent color coding\n",
    "    custom_palette = ['#a1c9f4', '#b9f2f0', '#8de5a1', '#ffb482', '#fab0e4']\n",
    "    \n",
    "    # Set custom order for assemblers\n",
    "    custom_order = [\n",
    "        'CarpeDeam\\n(safe mode)',\n",
    "        'CarpeDeam\\n(unsafe mode)',\n",
    "        'PenguiN',\n",
    "        'MEGAHIT',\n",
    "        'metaSPAdes'\n",
    "    ]\n",
    "    \n",
    "    assembler_order = sorted(df[\"assembler_final\"].unique(), key=lambda x: custom_order.index(x))\n",
    "    \n",
    "    # Convert 'assembler_final' to categorical type with custom order\n",
    "    df['assembler_final'] = pd.Categorical(df['assembler_final'], categories=assembler_order, ordered=True)\n",
    "    \n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Set custom order for coverages\n",
    "    coverage_order = [\"3\", \"5\", \"10\"]\n",
    "    df['coverage'] = pd.Categorical(df['coverage'], categories=coverage_order, ordered=True)\n",
    "    \n",
    "    # Determine the number of unique values for dataset_clean\n",
    "    datasets = sorted(df['dataset_clean'].unique())\n",
    "    \n",
    "    # Set up the subplots grid with appropriate size\n",
    "    fig_width = 12\n",
    "    fig_height = 10\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(fig_width, fig_height), sharey=False)\n",
    "    \n",
    "    handles, labels = None, None  # Initialize handles and labels for legend\n",
    "    \n",
    "    # Plot each subplot\n",
    "    plot_idx = 0\n",
    "    for dataset in datasets:\n",
    "        for coverage in coverage_order:\n",
    "            i, j = divmod(plot_idx, 3)  # Determine subplot position\n",
    "            if i < 3 and j < 3:\n",
    "                ax = axs[i, j]\n",
    "                subset = df[(df['dataset_clean'] == dataset) & (df['coverage'] == coverage)]\n",
    "                \n",
    "                if not subset.empty:\n",
    "                    barplot = sns.barplot(\n",
    "                        x='UniqueHits', \n",
    "                        y='assembler_final', \n",
    "                        hue='assembler_final', \n",
    "                        data=subset, \n",
    "                        ax=ax, \n",
    "                        palette=custom_palette, \n",
    "                        hue_order=assembler_order,\n",
    "                        errorbar=None,\n",
    "                        dodge=False,\n",
    "                        orient='h',  # Set orientation to horizontal\n",
    "                        width=bar_width\n",
    "                    )\n",
    "                    ax.set_title(f'Dataset: {dataset}, Coverage: {coverage}X')\n",
    "                    ax.set_ylabel('Assembler')\n",
    "                    ax.set_xlabel('# annotated proteins detected')\n",
    "                    ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "                    #ax.legend().set_visible(False)\n",
    "                    \n",
    "                    if handles is None and labels is None:\n",
    "                        handles, labels = ax.get_legend_handles_labels()\n",
    "                        \n",
    "                plot_idx += 1\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i * 3 + j >= plot_idx:\n",
    "                fig.delaxes(axs[i][j])\n",
    "    \n",
    "    # Add a single legend below the plot\n",
    "    if handles and labels:\n",
    "        fig.legend(handles, labels, title='Assembler', bbox_to_anchor=(0.5, -0.05), loc='upper center', ncol=len(labels))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/proteins_horizontal_fasta_prokka_repro.svg', format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2abd4-13c2-48de-9f8b-59f368b8354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_results = curate_df(datasets, configs, \"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa327af-df15-43e7-ab30-7cd72cf885ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_correct_horizontal(protein_results, \"high\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
