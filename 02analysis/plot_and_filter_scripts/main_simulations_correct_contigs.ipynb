{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d167c6c-06a6-4dd2-9c83-85867017f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee711b-9592-4114-9881-ec403532eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5sum(x):\n",
    "    return hashlib.md5(x.encode(\"utf-8\")).hexdigest()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4458945-1682-44b7-9205-0c2cdcff51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['carpedeam2.configSafe', 'carpedeam2.configUnsafe', 'megahit.config0', 'penguin.config0', 'spades.config0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b6b38-60f9-4196-b0f0-ebc68f540f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"ancientCalc\", \"ancientGut\", \"ancientHorse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd2524-c120-4976-84d3-d7b0d8c4c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"gut_sum_high_c3\", \"gut_sum_high_c5\", \"gut_sum_high_c10\", \"gut_sum_mid_c3\", \"gut_sum_mid_c5\", \"gut_sum_mid_c10\", \\\n",
    " \"calc_2095_high_c3\", \"calc_2095_high_c5\", \"calc_2095_high_c10\", \"calc_2095_mid_c3\", \"calc_2095_mid_c5\", \"calc_2095_mid_c10\", \\\n",
    " \"horse_sum_high_c3\", \"horse_sum_high_c5\", \"horse_sum_high_c10\", \"horse_sum_mid_c3\", \"horse_sum_mid_c5\", \"horse_sum_mid_c10\"]\n",
    "\n",
    "labels_clean = [\n",
    "    \"Gut:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Gut:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Gut:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 3X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 5X\",\n",
    "    \"Gut:\\nMid Damage; Cov. 10X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Calculus:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 3X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 5X\",\n",
    "    \"Calculus:\\nMid Damage; Cov. 10X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 3X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 5X\",\n",
    "    \"Bone:\\nHigh Damage; Cov. 10X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 3X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 5X\",\n",
    "    \"Bone:\\nMid Damage; Cov. 10X\"\n",
    "]\n",
    "\n",
    "labels_dict = {key: get_md5sum(key) for key in labels}\n",
    "labels_dict_inv = {value: key for key, value in labels_dict.items()}\n",
    "print(labels_dict_inv)\n",
    "\n",
    "labels_dict_clean = {labels[i] : labels_clean[i] for i in range(len(labels))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb0df5-ee60-4aff-8da0-e44a2f26b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_assembler(cell):\n",
    "    if \"carpedeam\" in cell:\n",
    "        return \"CarpeDeam\"\n",
    "    elif \"penguin\" in cell:\n",
    "        return \"PenguiN\"\n",
    "    elif \"megahit\" in cell:\n",
    "        return \"MEGAHIT\"\n",
    "    elif \"spades\" in cell:\n",
    "        return \"metaSPAdes\"\n",
    "    else:\n",
    "        return cell  # Return the cell as is if none of the conditions are met\n",
    "\n",
    "def adjust_assemblerconfig(row):\n",
    "    if row[\"assembler\"] == \"CarpeDeam\":\n",
    "        if \"Safe\" in row[\"file\"]:\n",
    "            return \"CarpeDeam (safe mode)\"\n",
    "        elif \"Unsafe\" in row[\"file\"]:\n",
    "            return \"CarpeDeam (unsafe mode)\"\n",
    "        else:\n",
    "            return \"CarpeDeam\\n(safe mode)\"\n",
    "    else:\n",
    "        return row[\"assembler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc8fba-bd5f-4da6-b4ea-7f7e4803d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_contigs(directory, min_length, configs):\n",
    "    # Find all FASTA files in the specified directory\n",
    "    fasta_files = glob.glob(os.path.join(directory, \"*.fasta\"))\n",
    "    \n",
    "    # Dictionary to store the information\n",
    "    contig_info = {}\n",
    "\n",
    "    for file in fasta_files:\n",
    "\n",
    "        if not any(config in file for config in configs):\n",
    "            continue\n",
    "        \n",
    "        count = sum(1 for record in SeqIO.parse(file, \"fasta\") if len(record.seq) >= min_length)\n",
    "\n",
    "        name = os.path.basename(file)\n",
    "\n",
    "        assembler = re.search(r'assm.([a-zA-Z0-9]+).config', name).group(1)\n",
    "        label = re.match(r'([a-z0-9]+).raw', name).group(1)\n",
    "        config = re.search(r'config(\\d+)', name).group(1)\n",
    "        \n",
    "        contig_info[name] = [count, assembler, label, config]\n",
    "\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame.from_dict(contig_info, orient='index', columns=['Count', 'Assembler', 'Label', 'Config'])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'Filename'}, inplace=True)\n",
    "\n",
    "    # Add additional columns\n",
    "    df[\"assemblerconfig\"] = df[\"Assembler\"] + \" \" + df[\"Config\"]\n",
    "    df[\"assembler_clean\"] = df[\"Assembler\"].apply(map_assembler)\n",
    "    df[\"assembler_final\"] = df.apply(adjust_assemblerconfig, axis=1)\n",
    "    df[\"label\"] = df[\"Label\"].astype(str)\n",
    "    df[\"label_human\"] = df[\"Label\"].map(labels_dict_inv)\n",
    "    df[\"label_clean\"] = df[\"label_human\"].replace(labels_dict_clean)\n",
    "    df[\"dataset_clean\"] = df[\"label_clean\"].str.split(\":\").str[0]\n",
    "    df[\"coverage\"] = df[\"label_human\"].str.split(\"_\").str[3].str[1::]\n",
    "    df[\"damage\"] = df[\"label_human\"].str.split(\"_\").str[2]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc6eeb-8780-45dd-b592-76769b50269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_df(datasets, min_length):\n",
    "\n",
    "    dfs = []\n",
    "    for data in datasets:\n",
    "        directory = f\"data/{data}/results/assembly_clean\"\n",
    "        df = filter_contigs(directory, min_length, configs)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c870d9-1760-459c-9e99-1c6aa3f9d2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80f1b4d7-c499-4c67-a9ef-afd8549c0306",
   "metadata": {},
   "source": [
    "# Get subset of correct sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070d6cf-788c-40e3-9bf8-cc1ef14e1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fastas(fileA, fileB, output):\n",
    "    # Read sequences from fileB and store their IDs in a set\n",
    "    fileB_ids = set(record.id for record in SeqIO.parse(fileB, \"fasta\"))\n",
    "    \n",
    "    # Open the output file for writing\n",
    "    with open(output, \"w\") as output_handle:\n",
    "        # Read sequences from fileA\n",
    "        for record in SeqIO.parse(fileA, \"fasta\"):\n",
    "            # Write sequences to output if their ID is not in fileB\n",
    "            if record.id not in fileB_ids:\n",
    "                SeqIO.write(record, output_handle, \"fasta\")\n",
    "\n",
    "    print(f\"Sequences from {fileA} that are not in {fileB} have been written to {output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778c62a-d60d-4310-846a-90e10de9d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(datasets, configs):\n",
    "    for data in datasets: \n",
    "        # Define patterns for fileA and fileB\n",
    "        fileA_pattern = f\"data/{data}/results/assembly/*.fasta\"\n",
    "        fileB_pattern = f\"data/{data}/results/assembly-evaluation-quast/*/combined_reference/contigs_reports/*.fa\"\n",
    "        \n",
    "        # Find files matching the patterns\n",
    "        fileA_list = glob.glob(fileA_pattern)\n",
    "        fileB_list = glob.glob(fileB_pattern)\n",
    "        \n",
    "        fileA_list = [f for f in fileA_list if any(config in f for config in configs)]\n",
    "        fileB_list = [f for f in fileB_list if any(config in f for config in configs)]\n",
    "        \n",
    "        # print(fileA_list)\n",
    "        # print(fileB_list)\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = f\"data/{data}/results/assembly_clean\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Iterate over fileA_list and find the corresponding fileB\n",
    "        for fileA in fileA_list:\n",
    "            # Extract the identifier from fileA\n",
    "            identifier = os.path.basename(fileA).split('_')[0].removesuffix(\".fasta\")\n",
    "            \n",
    "            # Find the corresponding fileB\n",
    "            fileB = next((f for f in fileB_list if identifier in f), None)\n",
    "            \n",
    "            if fileB:\n",
    "                # Define the output file name\n",
    "                output_file = os.path.join(output_dir, os.path.basename(fileA))\n",
    "                \n",
    "                # Compare FASTA files and create the output file\n",
    "                compare_fastas(fileA, fileB, output_file)\n",
    "            else:\n",
    "                print(f\"No matching fileB found for {fileA}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd48735-b21f-4dd0-95cf-cdbb3acebf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subset(datasets, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf40084-d18b-478e-8eea-0f26d5bf6d8c",
   "metadata": {},
   "source": [
    "# Plot number of correct sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed68757-6c6d-40a1-9a1a-0ae99ed79bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_correct(df_orig, damage, minLen, bar_width=0.6):\n",
    "    # Filter dataframe based on damage\n",
    "    df = df_orig[df_orig[\"damage\"] == damage]\n",
    "    \n",
    "    # Define a custom palette for consistent color coding\n",
    "    custom_palette = ['#a1c9f4', '#b9f2f0', '#8de5a1', '#ffb482', '#fab0e4']\n",
    "    \n",
    "    # Set custom order for assemblers\n",
    "    custom_order = [\n",
    "        'CarpeDeam\\n(safe mode)',\n",
    "        'CarpeDeam\\n(unsafe mode)',\n",
    "        'PenguiN',\n",
    "        'MEGAHIT',\n",
    "        'metaSPAdes'\n",
    "    ]\n",
    "    \n",
    "    assembler_order = sorted(df[\"assembler_final\"].unique(), key=lambda x: custom_order.index(x))\n",
    "    \n",
    "    # Convert 'assembler_final' to categorical type with custom order\n",
    "    df['assembler_final'] = pd.Categorical(df['assembler_final'], categories=assembler_order, ordered=True)\n",
    "    \n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Set custom order for coverages\n",
    "    coverage_order = [\"3\", \"5\", \"10\"]\n",
    "    df['coverage'] = pd.Categorical(df['coverage'], categories=coverage_order, ordered=True)\n",
    "    \n",
    "    # Determine the number of unique values for dataset_clean\n",
    "    datasets = sorted(df['dataset_clean'].unique())\n",
    "    \n",
    "    # Set up the subplots grid with appropriate size\n",
    "    fig_width = 12\n",
    "    fig_height = 12\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(fig_width, fig_height), sharey=False)\n",
    "    \n",
    "    # Plot each subplot\n",
    "    plot_idx = 0\n",
    "    for dataset in datasets:\n",
    "        for coverage in coverage_order:\n",
    "            i, j = divmod(plot_idx, 3)  # Determine subplot position\n",
    "            if i < 3 and j < 3:\n",
    "                ax = axs[i, j]\n",
    "                subset = df[(df['dataset_clean'] == dataset) & (df['coverage'] == coverage)]\n",
    "                \n",
    "                if not subset.empty:\n",
    "                    sns.barplot(\n",
    "                        x='assembler_final', \n",
    "                        y='Count', \n",
    "                        hue='assembler_final', \n",
    "                        data=subset, \n",
    "                        ax=ax, \n",
    "                        palette=custom_palette, \n",
    "                        hue_order=assembler_order,\n",
    "                        errorbar=None,\n",
    "                        dodge=False,\n",
    "                        width=bar_width\n",
    "                    )\n",
    "                    ax.set_title(f'Dataset: {dataset}, Coverage: {coverage}X')\n",
    "                    ax.set_xlabel('Assembler')\n",
    "                    if j == 0:\n",
    "                        ax.set_ylabel('# correct sequences > 2000bp')\n",
    "                    else:\n",
    "                        ax.set_ylabel('')\n",
    "                    ax.tick_params(axis='x', rotation=90, labelsize=10)\n",
    "                    #ax.legend().set_visible(False)\n",
    "                plot_idx += 1\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i * 3 + j >= plot_idx:\n",
    "                fig.delaxes(axs[i][j])\n",
    "    \n",
    "    \n",
    "    # Add a single legend below the plot if there are handles\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, title='Assembler', bbox_to_anchor=(0.5, -0.05), loc='upper center', ncol=len(labels))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/correct_contigs_repro.svg', format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028d19e-9012-4381-ac2d-9340f112b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curate_df(datasets, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badc33a-ac44-479d-bda9-7292cfeeea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_correct(df, \"high\", 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
