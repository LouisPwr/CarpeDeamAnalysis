{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96470617-ff6f-49d0-96bc-120d326e14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40067897-d9b2-4cd3-beba-44f1fc209c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5sum(x):\n",
    "    return hashlib.md5(x.encode(\"utf-8\")).hexdigest()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8caf83db-6311-42ff-acdb-771eb3576666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_assembler(cell):\n",
    "    if \"carpedeam\" in cell:\n",
    "        return \"CarpeDeam\"\n",
    "    elif \"penguin\" in cell:\n",
    "        return \"PenguiN\"\n",
    "    elif \"megahit\" in cell:\n",
    "        return \"MEGAHIT\"\n",
    "    elif \"spades\" in cell:\n",
    "        return \"metaSPAdes\"\n",
    "    else:\n",
    "        return cell  # Return the cell as is if none of the conditions are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246ae5e-c7b5-4236-94eb-69301f4392c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"ERR3579753\", \"ERR3579736\"]\n",
    "\n",
    "labels_dict = {key: get_md5sum(key) for key in labels}\n",
    "labels_dict_inv = {value: key for key, value in labels_dict.items()}\n",
    "print(labels_dict_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e541c4d1-91c9-4a42-be70-9dd17006b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = {'87bf691987' : 'EMN001', 'eebf379d54' : 'GDN001'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78aaeebb-e3eb-4855-ada5-e2c177bb9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, suffix):\n",
    "    aln_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(suffix):\n",
    "                aln_files.append(os.path.join(root, file))\n",
    "    return aln_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24dc5844-bb45-4efa-bd0d-cd5562caec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def venn_diagram_species(dfs, titles, dataset, third, number):\n",
    "    # Ensure the input is a list of DataFrames and titles\n",
    "    if not isinstance(dfs, list) or not all(isinstance(df, pd.DataFrame) for df in dfs):\n",
    "        raise ValueError(\"Input must be a list of pandas DataFrames.\")\n",
    "    if len(dfs) > 3:\n",
    "        print(\"More than 3 DataFrames provided. Only the first 3 will be used for the Venn diagram.\")\n",
    "        dfs = dfs[:3]\n",
    "\n",
    "    # Extract unique 'target' values from each DataFrame\n",
    "    sets = [set(df['reference'].unique()) for df in dfs]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if third == \"penguin\":\n",
    "        venn3(sets, titles, set_colors=(\"blue\", 'orange', 'green'))\n",
    "    else:\n",
    "        venn3(sets, titles, set_colors=(\"blue\", 'orange', 'red'))       \n",
    "\n",
    "    \n",
    "    if dataset == \"RISE\":\n",
    "        dataset = \"RISE397\"\n",
    "    \n",
    "    plt.title(f\"Taxonomy Assignment on Species Level:\\nNumber of Matches between Translated Contigs and Genome Taxonomy Database (GTDB)\\nDataset: {dataset}\")\n",
    "    #plt.savefig(f'taxonomy/taxonomy_{dataset}_{number}.svg', format=\"svg\")\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b673e3c0-8bfe-43f4-8c35-6cef4c1bd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_report_df(file):\n",
    "    \"\"\"\n",
    "    Returns a list of dataframes. Each dataframe belongs to a file/assembler. The analyzed files are from mmseq taxonomy:\n",
    "    (1) Target identifier\n",
    "    (2) Number of sequences aligning to target\n",
    "    (3) Unique coverage of target uniqueAlignedResidues / targetLength\n",
    "    (4) Target coverage alignedResidues / targetLength\n",
    "    (5) Average sequence identity\n",
    "    (6) Taxonomical information identifier, species, lineage\n",
    "    \"\"\"\n",
    "    \n",
    "    df_aln = pd.read_csv(file, sep='\\t', names=[\"target\", \"coveredBy\", \"uniqCov\", \"totalCov\", \"seq.Id.\", \"taxId\", \"species1\", \"species2\"])\n",
    "    df_aln[\"reference\"] = df_aln[\"target\"].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "    df_aln = df_aln[ df_aln[\"uniqCov\"] >= 0.9 ] #df_aln[\"uniqCov\"] >= 0.99\n",
    "    df_aln.reset_index(inplace=True)\n",
    "    \n",
    "    df_aln[\"file\"] = os.path.basename(file)\n",
    "    df_aln[\"dataLabel\"]=df_aln[\"file\"].str.split(\".\").str[0].map(sample_map)\n",
    "    df_aln[\"assembler\"] = df_aln[\"file\"].apply(lambda file: map_assembler(file))\n",
    "    \n",
    "    return df_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c43ad-124b-4db2-aae9-1d794ade32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOPHIT REPORT ANALYSIS\n",
    "\n",
    "assemblers = ['carpedeam.config0', 'megahit.config0', 'penguin.config0', 'spades.config0']\n",
    "samples = [\"GDN001\", \"EMN001\"]\n",
    "\n",
    "dic = {value: {} for value in samples}\n",
    "print(dic)\n",
    "for sample in samples:\n",
    "    path=f\"data/{sample}/results/assembly-easytaxonomy-eval_gtdb\"\n",
    "    files_aln = find_files(path, \"tophit_report\")\n",
    "    for file in files_aln:\n",
    "        if any(assembler in file for assembler in assemblers):\n",
    "            results = curate_report_df(file)\n",
    "            readname = results[\"dataLabel\"][0]\n",
    "            assembler_id = results[\"assembler\"][0]\n",
    "            dic[readname][assembler_id] = results\n",
    "\n",
    "\n",
    "for dataset in dic.keys():\n",
    "    try:\n",
    "        venn_diagram_species([dic[dataset][\"CarpeDeam\"], dic[dataset][\"MEGAHIT\"], dic[dataset][\"PenguiN\"]], [\"CarpeDeam\", \"MEGAHIT\", \"PenguiN\"], dataset, \"penguin\" ,1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        venn_diagram_species([dic[dataset][\"CarpeDeam\"], dic[dataset][\"MEGAHIT\"], dic[dataset][\"metaSPAdes\"]], [\"CarpeDeam\", \"MEGAHIT\", \"metaSPAdes\"], dataset, \"spades\", 2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
