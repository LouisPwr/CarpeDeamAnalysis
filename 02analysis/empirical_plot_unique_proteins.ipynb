{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96470617-ff6f-49d0-96bc-120d326e14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40067897-d9b2-4cd3-beba-44f1fc209c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5sum(x):\n",
    "    return hashlib.md5(x.encode(\"utf-8\")).hexdigest()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8caf83db-6311-42ff-acdb-771eb3576666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_assembler(cell):\n",
    "    if \"carpedeam\" in cell:\n",
    "        return \"CarpeDeam\"\n",
    "    elif \"penguin\" in cell:\n",
    "        return \"PenguiN\"\n",
    "    elif \"megahit\" in cell:\n",
    "        return \"MEGAHIT\"\n",
    "    elif \"spades\" in cell:\n",
    "        return \"metaSPAdes\"\n",
    "    else:\n",
    "        return cell  # Return the cell as is if none of the conditions are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3246ae5e-c7b5-4236-94eb-69301f4392c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eebf379d54': 'ERR3579753', '87bf691987': 'ERR3579736', 'b9fca77ede': 'ERR3579731', '7290ed61ac': 'ERR3579732'}\n"
     ]
    }
   ],
   "source": [
    "labels = [\"ERR3579753\", \"ERR3579736\"]\n",
    "\n",
    "labels_dict = {key: get_md5sum(key) for key in labels}\n",
    "labels_dict_inv = {value: key for key, value in labels_dict.items()}\n",
    "print(labels_dict_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e541c4d1-91c9-4a42-be70-9dd17006b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = {'87bf691987' : 'EMN001', 'eebf379d54' : 'GDN001'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78aaeebb-e3eb-4855-ada5-e2c177bb9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, suffix):\n",
    "    aln_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(suffix):\n",
    "                aln_files.append(os.path.join(root, file))\n",
    "    return aln_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dc59ef4-b482-43cb-8915-3dedb043bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_hits(dfs, titles, dataset, number):\n",
    "\n",
    "\n",
    "    assembler_order=[\"CarpeDeam\", \"MEGAHIT\", \"PenguiN\", \"metaSPAdes\"]\n",
    "    assembler_colors= ['#a1c9f4', '#ffb482','#8de5a1','#ff9f9b']\n",
    "   \n",
    "\n",
    "    # Ensure the input is a list of DataFrames and titles\n",
    "    if not isinstance(dfs, list) or not all(isinstance(df, pd.DataFrame) for df in dfs):\n",
    "        raise ValueError(\"Input must be a list of pandas DataFrames.\")\n",
    "\n",
    "    # Extract unique hits per assembler\n",
    "    unique_hits = [df['reference'].nunique() for df in dfs]\n",
    "\n",
    "    # Create a data frame for plotting\n",
    "    data = pd.DataFrame({'Assembler': titles, 'Unique Hits': unique_hits})\n",
    "\n",
    "    # Set the order of assemblers if provided\n",
    "    if assembler_order:\n",
    "        data = data.set_index('Assembler').reindex(assembler_order).reset_index()\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot horizontal bar chart using seaborn\n",
    "    sns.barplot(x='Unique Hits', y='Assembler', data=data, palette=assembler_colors, ax=ax)\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    ax.set_xlabel('Number of Unique Hits', fontsize=12)\n",
    "    ax.set_ylabel('Assembler', fontsize=12)\n",
    "\n",
    "    # Add values to bars\n",
    "    for i, v in enumerate(data['Unique Hits']):\n",
    "        ax.text(v + 0.1, i, str(v), va='center', fontsize=12)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if dataset == \"RISE\":\n",
    "        dataset = \"RISE397\"\n",
    "\n",
    "    plt.title(f\"Predicted ORFs Searched Against the UniRef100 Protein Database:\\nUnique Hits w. E-Value < 1e-5 and Aligned Length >= 100 \\nDataset: {dataset}\", fontsize=14)\n",
    "    plt.savefig(f'taxonomy/unique_hits_{dataset}_{number}.svg', format=\"svg\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673e3c0-8bfe-43f4-8c35-6cef4c1bd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_report_df(file):\n",
    "    \"\"\"\n",
    "    Returns a list of dataframes. Each dataframe belongs to a file/assembler. The analyzed files are from mmseq taxonomy:\n",
    "    (1) Query\n",
    "    (2) Target\n",
    "    (3) Seq.Id.\n",
    "    (4) Alignment Length\n",
    "    (5) Number of mismatches\n",
    "    (6) number of gap openings\n",
    "    (7) Start in Query\n",
    "    (8) End in Query\n",
    "    (9) Start in Target\n",
    "    (10) End in Target\n",
    "    (11) Eval\n",
    "    (12) bit score\n",
    "    \"\"\"\n",
    "    \n",
    "    df_aln = pd.read_csv(file, sep='\\t', names=[\"query\", \"target\", \"seq.Id.\", \"alnLen\", \"MM\", \"gaps\", \"startQuery\", \"EndQuery\", \"startTarget\", \"EndTarget\", \"Eval\", \"bit score\"])\n",
    "    df_aln[\"reference\"] = df_aln[\"target\"].str.rsplit('_', n=1).str[1]\n",
    "\n",
    "    df_aln = df_aln[ df_aln[\"seq.Id.\"] >= 0.35 ]\n",
    "    df_aln = df_aln[ df_aln[\"Eval\"] >= 1e-5 ]\n",
    "    df_aln = df_aln[ df_aln[\"alnLen\"] >= 100 ]\n",
    "\n",
    "    df_aln.reset_index(inplace=True)\n",
    "    \n",
    "    df_aln[\"file\"] = os.path.basename(file)\n",
    "    df_aln[\"dataLabel\"]=df_aln[\"file\"].str.split(\".\").str[0].map(sample_map)\n",
    "    df_aln[\"assembler\"] = df_aln[\"file\"].apply(lambda file: map_assembler(file))\n",
    "    \n",
    "    return df_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7a61c-f018-4ddc-9329-183b785914ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOPHIT REPORT ANALYSIS\n",
    "\n",
    "assemblers = ['carpedeam.config0', 'megahit.config0', 'penguin.config0', 'spades.config0']\n",
    "samples = [\"GDN001\", \"EMN001\"]\n",
    "#samples = [\"ECO004\", \"ECO004(UDG)\"]\n",
    "\n",
    "dic = {value: {} for value in samples}\n",
    "print(dic)\n",
    "for sample in samples:\n",
    "    path=f\"data/{sample}/results/assembly-mmseqs\"\n",
    "\n",
    "    files_aln = find_files(path, \".tsv\")\n",
    "    print(files_aln)\n",
    "    #dicSamples = {}\n",
    "    for file in files_aln:\n",
    "        if any(assembler in file for assembler in assemblers):\n",
    "            results = curate_report_df(file)\n",
    "            readname = results[\"dataLabel\"][0]\n",
    "            assembler_id = results[\"assembler\"][0]\n",
    "            dic[readname][assembler_id] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c060a-c164-47e5-a49d-5a023e5ca95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dic.keys():\n",
    "    plot_unique_hits([dic[dataset][\"CarpeDeam\"], dic[dataset][\"MEGAHIT\"], dic[dataset][\"PenguiN\"],dic[dataset][\"metaSPAdes\"]], [\"CarpeDeam\", \"MEGAHIT\", \"PenguiN\", \"metaSPAdes\"], dataset, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
